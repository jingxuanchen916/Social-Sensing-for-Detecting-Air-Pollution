{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation"
   ],
   "metadata": {
    "id": "3qD1h3MrziOD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QSTUB5MTNCZ",
    "outputId": "6df22ccd-1ea9-4f37-dea1-7334a97dc1e0"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5F_AsxMQRNl",
    "outputId": "3e8cd934-9c70-4b71-9c58-583dd6410a87"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji transformers"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification, pipeline"
   ],
   "metadata": {
    "id": "eOVQQiug1xnG"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "path = '/content/drive/MyDrive/Riza_Jingxuan/Year_3_Project/SS4DAP/Model/'"
   ],
   "metadata": {
    "id": "H3KCVtClz9jK"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NER"
   ],
   "metadata": {
    "id": "Uy_GMkA-zNqr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NER1_samrawal"
   ],
   "metadata": {
    "id": "l0l8Artoz3La"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "label_list = ['B-problem', 'B-treatment', 'I-test', 'I-treatment', 'B-test', 'O', 'I-problem']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path + 'NER1_samrawal')\n",
    "\n",
    "paragraph = '''Stalybridge GP Richard Bircher says he’s seen people with nosebleeds, bad coughs and sore eyes from the smoke as the fire still burns on Saddleworth Moor. 100 firefighters are now up there tackling it.'''\n",
    "tokens = tokenizer(paragraph)\n",
    "torch.tensor(tokens['input_ids']).unsqueeze(0).size()\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(path + 'NER1_samrawal', num_labels=len(label_list))\n",
    "predictions = model.forward(input_ids=torch.tensor(tokens['input_ids']).unsqueeze(0), attention_mask=torch.tensor(tokens['attention_mask']).unsqueeze(0))\n",
    "predictions = torch.argmax(predictions.logits.squeeze(), axis=1)\n",
    "predictions = [label_list[i] for i in predictions]\n",
    "\n",
    "words = tokenizer.batch_decode(tokens['input_ids'])\n",
    "print(pd.DataFrame({'ner': predictions, 'words': words}))"
   ],
   "metadata": {
    "id": "eFFTweoWTeDN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eb9eb718-5bc4-4da1-85ed-670599631636"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          ner         words\n",
      "0           O         [CLS]\n",
      "1           O            st\n",
      "2           O           aly\n",
      "3           O        bridge\n",
      "4           O            gp\n",
      "5           O       richard\n",
      "6           O         birch\n",
      "7           O            er\n",
      "8           O          says\n",
      "9           O            he\n",
      "10          O             ’\n",
      "11          O             s\n",
      "12          O          seen\n",
      "13          O        people\n",
      "14          O          with\n",
      "15  B-problem          nose\n",
      "16  B-problem           ble\n",
      "17  B-problem            ed\n",
      "18  B-problem             s\n",
      "19          O             ,\n",
      "20          O           bad\n",
      "21  I-problem         cough\n",
      "22  B-problem             s\n",
      "23          O           and\n",
      "24  B-problem          sore\n",
      "25  I-problem          eyes\n",
      "26          O          from\n",
      "27          O           the\n",
      "28          O         smoke\n",
      "29          O            as\n",
      "30          O           the\n",
      "31          O          fire\n",
      "32          O         still\n",
      "33          O         burns\n",
      "34          O            on\n",
      "35          O        saddle\n",
      "36          O         worth\n",
      "37          O          moor\n",
      "38          O             .\n",
      "39          O           100\n",
      "40          O  firefighters\n",
      "41          O           are\n",
      "42          O           now\n",
      "43          O            up\n",
      "44          O         there\n",
      "45          O          tack\n",
      "46          O          ling\n",
      "47          O            it\n",
      "48          O             .\n",
      "49          O         [SEP]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NER2_alvaroalon2"
   ],
   "metadata": {
    "id": "K_wf6Tkl1e-7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "label_list = ['B-DISEASE', 'I-DISEASE', 'O']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path + 'NER2_alvaroalon2')\n",
    "model = AutoModelForTokenClassification.from_pretrained(path + 'NER2_alvaroalon2', num_labels=len(label_list))\n",
    "\n",
    "paragraph = '''Stalybridge GP Richard Bircher says he’s seen people with nosebleeds, bad coughs and sore eyes from the smoke as the fire still burns on Saddleworth Moor. 100 firefighters are now up there tackling it.'''\n",
    "tokens = tokenizer(paragraph)\n",
    "torch.tensor(tokens['input_ids']).unsqueeze(0).size()\n",
    "\n",
    "predictions = model.forward(input_ids=torch.tensor(tokens['input_ids']).unsqueeze(0), attention_mask=torch.tensor(tokens['attention_mask']).unsqueeze(0))\n",
    "predictions = torch.argmax(predictions.logits.squeeze(), axis=1)\n",
    "predictions = [label_list[i] for i in predictions]\n",
    "\n",
    "words = tokenizer.batch_decode(tokens['input_ids'])\n",
    "print(pd.DataFrame({'ner': predictions, 'words': words}))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g93di2g42LJu",
    "outputId": "d9e297d2-ca43-4278-9a26-a6536c59678e"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          ner         words\n",
      "0           O         [CLS]\n",
      "1           O            St\n",
      "2           O           aly\n",
      "3           O        bridge\n",
      "4           O            GP\n",
      "5           O       Richard\n",
      "6           O         Birch\n",
      "7           O            er\n",
      "8           O          says\n",
      "9           O            he\n",
      "10          O             ’\n",
      "11          O             s\n",
      "12          O          seen\n",
      "13          O        people\n",
      "14          O          with\n",
      "15  B-DISEASE          nose\n",
      "16  B-DISEASE           ble\n",
      "17  B-DISEASE           eds\n",
      "18          O             ,\n",
      "19  B-DISEASE           bad\n",
      "20  I-DISEASE         cough\n",
      "21  I-DISEASE             s\n",
      "22          O           and\n",
      "23  B-DISEASE          sore\n",
      "24  I-DISEASE          eyes\n",
      "25          O          from\n",
      "26          O           the\n",
      "27          O         smoke\n",
      "28          O            as\n",
      "29          O           the\n",
      "30          O          fire\n",
      "31          O         still\n",
      "32          O         burns\n",
      "33          O            on\n",
      "34          O           Sad\n",
      "35          O           dle\n",
      "36          O         worth\n",
      "37          O          Moor\n",
      "38          O             .\n",
      "39          O           100\n",
      "40          O  firefighters\n",
      "41          O           are\n",
      "42          O           now\n",
      "43          O            up\n",
      "44          O         there\n",
      "45          O            ta\n",
      "46          O        ckling\n",
      "47          O            it\n",
      "48          O             .\n",
      "49          O         [SEP]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment"
   ],
   "metadata": {
    "id": "r2OJZrvGzfAh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment0_irrelevant"
   ],
   "metadata": {
    "id": "5L4B1eWc2lty"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(path + 'Sentiment0_irrelevant')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(path + 'Sentiment0_irrelevant', num_labels=2)\n",
    "\n",
    "generator = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "generator(['What a nice day!', 'Hills Ablaze Above Manchester as U.K. Wildfire Rages for 4th Day https://t.co/vArOufXTet https://t.co/vArOufXTet', '@JBBuczek Quite happy to take a little off you. Raging wildfire on Saddleworth Moor near Manchester. They seem to think some heavy rain is the only thing now to put it out. But whatever the weather enjoy your day John.'])"
   ],
   "metadata": {
    "id": "nBRb0xS4zgYf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d1c029fd-cc40-41b4-eaed-b8d06ea02486"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.8281125426292419},\n",
       " {'label': 'LABEL_1', 'score': 0.9838178157806396},\n",
       " {'label': 'LABEL_1', 'score': 0.9850481748580933}]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment1_cardiffnlp"
   ],
   "metadata": {
    "id": "1-qjX_sp3JxI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(path + 'Sentiment1_cardiffnlp')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(path + 'Sentiment1_cardiffnlp', num_labels=3)\n",
    "\n",
    "generator = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "generator(['big wildfire', 'I can actually smell smoke and see it in the air in Salford. Is this from the Saddleworth moors fire?'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69IYhgS125lc",
    "outputId": "056d4deb-9f76-4415-a777-db1551a7d7bb"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9514998197555542},\n",
       " {'label': 'LABEL_0', 'score': 0.9926793575286865}]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment2_finiteautomata"
   ],
   "metadata": {
    "id": "zHpRaVIL3clp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(path + 'Sentiment2_finiteautomata')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(path + 'Sentiment2_finiteautomata', num_labels=3)\n",
    "\n",
    "generator = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "generator(['big wildfire', 'I can actually smell smoke and see it in the air in Salford. Is this from the Saddleworth moors fire?'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giFoegWB3YbY",
    "outputId": "809084d9-def0-404f-df80-9e9377065ec8"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'NEU', 'score': 0.9853805899620056},\n",
       " {'label': 'NEG', 'score': 0.9958932399749756}]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "yK4S8Y1g3gZr"
   },
   "execution_count": 9,
   "outputs": []
  }
 ]
}
